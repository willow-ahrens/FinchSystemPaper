\begin{abstract}
\HIDE{From FORTRAN to Numpy, arrays have revolutionized how we express computation.  Arrays are the highest-performing datastructure with a long history of investment and innovation, from hardware support to compiler technology.  However, arrays can only handle dense rectilinear integer grids. Real world arrays often contain underlying structure, such as sparsity, runs of repeated values, or symmetry. We describe a compiler, Finch, which adapts existing programs and interfaces to the structure and sparsity of the inputs. Finch enables programmers to capture complex, real-world data scenarios with the same productivity they expect from dense arrays. Our approach enables new loop optimizations across multiple domains, unifying techniques such as sparse tensors, databases, and lossless compression. }

\HIDE{
Of the nearly 44 zettabytes of data humans have gathered to date, most of it is collected, processed, and stored as multi-dimensional arrays.
Multi-dimensional arrays are the most prominent data type from the first programming language FORTRAN to modern Numpy.
Furthermore, multi-dimensional arrays are the highest-performing data structure with a long history of investment and innovation, from hardware support to compiler technology.
Arrays in these, and almost all prominent systems, can only handle dense rectilinear integer grids.
However, a large portion of the data, either obtained from nature or generated by humans, have structure.  

Over the years compiler researchers have valiantly attempted to put sparse tensor algebra on the same compiler transformation and code generation footing as dense tensor algebra and array codes. So far this has failed in both scope of the ambition and execution of comparable features.  Real world data have structure beyond sparsity including runs of repeated values, dense blocks or diagonals, ragged edges, or symmetry. 
Thus, focusing only on sparsity limits the scope needed to handle the staggering variety of data. Second, the arrays and loops abstraction introduced in FORTRAN supports lot more complex control flow not supported by einsum based modern sparse array compilers. For example, complex control flow such as conditional branches and early exits are needed for many important computations such as graph analytics. 
 
In this paper, we describe a compiler, Finch,
which adapts existing programs and interfaces to the structure and sparsity of the inputs. Finch enables
programmers to capture real-world scenarios with structured data and complex control flow with the same productivity they expect from dense arrays. Our approach enables new loop optimizations across multiple domains, unifying techniques in areas such as
sparse tensors, databases, and lossless compression.
We hope to truly bring tensor algebra on structured data to the same compiler transformation and code generation footing as dense tensor algebra and array codes.}

From FORTRAN to Numpy, arrays have revolutionized how we express computation. However, arrays in these, and almost all prominent systems, can only handle dense rectilinear integer grids.
Real world arrays often contain underlying structure, such as sparsity, runs of repeated values, or symmetry.
Support for structured data is fragmented and incomplete.
Existing frameworks limit the array structures and program control flow they support to better simplify the problem.

In this work, we propose a new programming language, Finch, which supports \textit{both}
flexible control flow and diverse data structures. Finch facilitates a programming model which
resolves the challenges of computing over structured arrays by combining control flow and data
structures into a common representation where they can be co-optimized. In particular,
Finch automatically specializes the control flow to the data so that performance engineers can
focus on experimenting with many algorithms. Finch supports a familiar programming language
of loops, statements, if conditions, breaks, etc, over a wide variety of array structures, such as
sparsity, run-length-encoding, symmetry, triangles, padding, or blocks. Finch reliably utilizes the key
properties of structure, such as structural zeros, repeated values, or clustered non-zeros. We show that this leads to dramatic speedups in operations such as spmv and spgemm, image processing, graph analytics, and a high-level tensor operator fusion interface.
\end{abstract}