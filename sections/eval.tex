
\section{Case Studies}

We evaluate Finch on a broad set of applications to showcase it's efficiency,
flexibility, and expressibility. All of our implementations highlight the
benefits of data structure and algorithm co-design.  Our implementation of
sparse-sparse-matrix multiply (SpGEMM) translates classical lessons from sparse
performance engineering into the language of Finch, using temporaries and
randomly-accessible workspace formats to efficiently implement the three main
approaches. Our study of sparse-matrix-dense-vector multiply (SpMV) highlights
the benefits of precise structural specialization. Our studies of image
morphology and graph applications show how Finch's programming model can express more complex
real-world kernels. Finally, we explain
how flexible operators, formats, and indexing expressions in Finch have
supported a flexible implementation of the Python Array API, supporting fused execution.

All experiments were run on a single core of a 12-core 2-socket Intel Xeon E5-2695 v2 running at
2.40GHz with 128GB of memory. Finch is implemented in Julia v1.9, targeting LLVM
through Julia. All timings are the minimum of 10,000 runs or 5s of measurement,
whichever happens first.

\input{sections/eval/spmv}
\input{sections/eval/spgemm}
\input{sections/eval/graphs}
\input{sections/eval/morphology}
\input{sections/eval/api}