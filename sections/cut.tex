\HIDE{From FORTRAN to NumPy, arrays have revolutionized how we express computation.  Arrays are the highest-performing datastructure with a long history of investment and innovation, from hardware support to compiler technology.  However, arrays can only handle dense rectilinear integer grids. Real world arrays often contain underlying structure, such as sparsity, runs of repeated values, or symmetry. We describe a compiler, Finch, which adapts existing programs and interfaces to the structure and sparsity of the inputs. Finch enables programmers to capture complex, real-world data scenarios with the same productivity they expect from dense arrays. Our approach enables new loop optimizations across multiple domains, unifying techniques such as sparse tensors, databases, and lossless compression. }

\HIDE{
Of the nearly 44 zettabytes of data humans have gathered to date, most of it is collected, processed, and stored as multi-dimensional arrays.
Multi-dimensional arrays are the most prominent data type from the first programming language FORTRAN to modern Numpy.
Furthermore, multi-dimensional arrays are the highest-performing data structure with a long history of investment and innovation, from hardware support to compiler technology.
Arrays in these, and almost all prominent systems, can only handle dense rectilinear integer grids.
However, a large portion of the data, either obtained from nature or generated by humans, have structure.  

Over the years compiler researchers have valiantly attempted to put sparse tensor algebra on the same compiler transformation and code generation footing as dense tensor algebra and array codes. So far this has failed in both scope of the ambition and execution of comparable features.  Real world data have structure beyond sparsity including runs of repeated values, dense blocks or diagonals, ragged edges, or symmetry. 
Thus, focusing only on sparsity limits the scope needed to handle the staggering variety of data. Second, the arrays and loops abstraction introduced in FORTRAN supports lot more complex control flow not supported by einsum based modern sparse array compilers. For example, complex control flow such as conditional branches and early exits are needed for many important computations such as graph analytics. 
 
In this paper, we describe a compiler, Finch,
which adapts existing programs and interfaces to the structure and sparsity of the inputs. Finch enables
programmers to capture real-world scenarios with structured data and complex control flow with the same productivity they expect from dense arrays. Our approach enables new loop optimizations across multiple domains, unifying techniques in areas such as
sparse tensors, databases, and lossless compression.
We hope to truly bring tensor algebra on structured data to the same compiler transformation and code generation footing as dense tensor algebra and array codes.}
% \teo{
% Due to this fine grained mixing of control flow and data structures, we dub a new programming model for Finch: ``Fine Grained Data Structure Driven Array Programming''.
% %
% Finch supports \textit{both} flexible programming constructs and diverse data structures. 
% %
% Finch supports a similar programming language of loops, statements, if conditions, breaks, etc, over a wide variety of array structures, such as sparsity, run-length-encoding, symmetry, triangles, padding, or blocks.
% %
% The Finch compiler uses the structure
% of the data to generate efficient implementations of these programs by predictably converting the control flow into the same representation as the data, Looplets~\cite{ahrens_looplets_2023}.}


%% Many variations of this problem.
%By combining many data structures and control flows into a single language, a performance engineer could use a sufficiently predicable and fine grained compiler to find efficient programs.
%
%We dub this model, ``Datastructure-driven Array Programming'' in which the programmer specifies the structure of the data separately from the program, but then can reasonably iterate on the two with a compiler that predicable combines them, leading to efficient code eventually.
%
%(Note quite sure how much comes after this)
%We should say the predicability is generating only the non-zeros! We leverage the intiial stuff of Finch to say we will in order generate the code that only grabs the non-zeros, modified in certain ways based on the fine grained ordering of computation)
%(Use the below comment as an example - where the old paragraph talked about merging two lists.)


%In this work, we propose a new programming model we call ``Datastructure-driven Array Programming'' in which the programmer specifies the structure of the data separately from the program, and the compiler uses these two descriptions to generate efficient code.\saman{Is this new? TACO did something similar?} In this model, performance engineers can more efficiently search the
%complex landscape of programs and datastructures to find the best implementation. In this programming model, we can express certain concepts in programs, and others in data. For example, if we wish to merge two sorted lists, we express this as two sparse vectors which are true whenever the list contains the key in question, and we iterate over the \textit{entire} space of keys, writing to the output list whenever either of the vectors are true.
%While the order in which we iterate over the data is expressed in the program, which datapoints are of interest and how to find them is expressed in the data.


%Taichi enriches single static assignment form with specialized instruction for accessing a single sparse structure drawn from a particular class, which is why it supports the most control flow for a single sparse structure~\cite{hu_taichi_2019}.
%
%Furthermore, the limits and advantages of a DSL can be traced to the specific coupling of a program's control flow with the data structure: many new TACO features required modifying algorithms that worked with TACO's merge lattices and Tiramisu can express programs that Halide can't because Tiramisu uses a polyhedral model as opposed to a model built on iterating over regular grids~\cite{kjolstad_tensor_2017, henry_compilation_2021, senanayake2020sparse, baghdadi2019tiramisu}.
%
%In this work, we will choose  a new representation of a program's data structures and control flows that covers a wide range of programs.
%
%However, simply combining a large variety of structured data with a large variety of programs does not necessarily yield a performance advantages.
%
%After all previous implementations choose to tightly couple to a specific data structure in part to ensure the data structures are iterated over efficiently.
%
%To find and produce efficient programs for structured data, we must overcome two challenges that occur when we intersect complex control flow with structured data:

%before introducing this, we must discuss performance: if we want to also produce efficient code for structured data, we face two challenges.



%build on some conception of an iteration space: TACO has merge lattices, Polyhedral compilers rely on the polyhedral model, Halide and Corra uses rectangular intervals, and so on.
%
%And we believe the limitations of these systems can be traced back to their specific conceptions.} \willow{I agree with what this sentence is saying, but I'm concerned that the sentiment is unclear, because here it may seem like we say "iteration space bad" and later say "iteration space good". Can we perhaps adjust here to say may of these special purpose compilers use overly restrictive models of the iteration space of the program, but that Finch is good because it uses general control flow to express a wider variety of iteration spaces. At a high level, we need to define "iteration space" or "control flow" or "Looplets" if we want to use them in the intro, and depending on how much we want to use these words we may want to avoid them here.}
%
% \teo{For example, each modification to expressions that TACO could support required modifying the merge lattice algorithms\cite{kjolstad_tensor_2017, henry_compilation_2021, senanayake2020sparse} and several programs could not be supported in Halide, but could be in Tiramisu due to the limitations of a rectangular iteration space~\cite{baghdadi2019tiramisu}.
% %
% And many iteration space concepts simply don't allow for skipping work that isn't simply the complement of an interval.
% %
% In our work, we will show how we can use Looplets as our main tool to manage the iteration spaces of our computations and data structures.
% %
% However, to support as many data structures and iteration spaces as is implied above, we face two challenges if we want to also produce efficient code over structured data.
% }
%We see two main challenges to writing efficient code over structured data.
\teo{How about:
A Looplet based level-format abstraction.
%
Although many systems (TACO, Taichi, SPF, Ebb)~\cite{chou2018format,  hu_taichi_2019, strout2018sparse, bernstein2016ebb} features a flexible data structure description language for array-like computations, we show that we can describe more level formats than any other by a level format abstraction designed to target Looplets in the context of an array programming language with fine-grained control flow. 
%
The first such set of formats to efficiently capture banded,
triangular, run-length-encoded, or sparse datasets, and any combination thereof.
}


with key level formats that completely capture the main structural properties of data. for expressing the structure of data
hierarchically.\saman{level formats were done in TACO.} The first such set of formats to efficiently capture banded,
triangular, run-length-encoded, or sparse datasets, and any combination thereof.

%
\teo{
The Finch language offers extensible abstractions for elements of control flow (conditionals and indexing expressions) that the Finch compiler predictably converts into the same structured representation used to describe arrays.
%
By controlling how control flow is lowered into this representation, a programmer can control how structured data is combined with control flow to produce a single control flow, the program.
%
We observe that this strategy naturally extends the dense solution.
}
\teo{I think we can back it up in two ways:
1. We need to modify the semantics to focus when on when things are converted into Looplets
2. We need to highlight the specifics in the case studies: in particular, the blur and the symmetric operations. If we do triangle counting or something like that, we could maybe talk about that a bit.
}
\teo{
\item Extensibility of the language and compiler with respect to data structures and control flow: (Maybe put stuff about the data structure extensibility here?)
}

   
\scriptsize
\noindent % This ensures the minipages fill the page width
\begin{minipage}{0.4\linewidth}
\begin{align*}
    \finchliteral(val \in \mathbb{V}) &:= \text{\mintinline{julia}{val}} \\
    \finchvalue(ex \in \mathbb{S}, type \in \mathbb{T}) &:= \text{\mintinline{julia}{ex :: type}} \\
    \finchtensor(name \in \mathbb{S}) &:= \text{\mintinline{julia}{name}} \\
    \finchindex(name \in \mathbb{S}) &:= \text{\mintinline{julia}{name}} \\
    \finchvar(name \in \mathbb{S}) &:= \text{\mintinline{julia}{name}} \\
    \finchextent(a \in E, b \in E) &:= \text{\mintinline{julia}{a : b}} \\
    \finchcall(f \in E, args\ldots \in E) &:= \text{\mintinline{julia}{f(args...)}} \\
    \finchaccess(tns \in T, idxs\ldots \in E) &:= \text{\mintinline{julia}{tns[idxs...]}} \\
    \finchfreeze(tns \in T) &:= \text{\mintinline{julia}{@freeze(tns)}} \\
    \finchthaw(tns \in T) &:= \text{\mintinline{julia}{@thaw(tns)}} \\
    \finchmode(tns \in T) &:= \text{\mintinline{julia}{@mode(tns)}} \\
\end{align*}
\end{minipage}%
\begin{minipage}{0.5\linewidth}
\begin{align*}
    \mathbb{V} &:= \text{the set of all values.} \\
    \mathbb{S} &:= \text{the set of all symbols.} \\
    \mathbb{T} &:= \text{the set of all types.} \\
    I &:= \finchindex \\
    A &:= \finchaccess \\
    V &:= \finchvar \\
    T &:= \finchtensor \\
    E &:= \finchliteral \mid \finchvalue \mid \finchindex \\
        &\quad \mid \finchvar \mid \finchextent \mid \finchcall \mid \finchaccess \\
    S &:= \finchassign \mid \finchloop \mid \finchdefine \\
        &\quad \mid \finchsieve \mid \finchblock \\
\end{align*}
\end{minipage}%
\begin{align*}
    \finchdeclare(tns \in T, init \in E, dims\ldots \in E) &:= \text{\mintinline{julia}{tns .= init(dims...)}} \\
    \finchassign(lhs \in A, op \in E, rhs \in E) &:= \text{\mintinline{julia}{lhs <<op>>= rhs}} \\
    \finchloop(idx \in I, range \in E, body \in S) &:= \text{\mintinline{julia}{for idx = range; body end}} \\
    \finchdefine(var \in V, val \in E, body \in S) &:= \text{\mintinline{julia}{let var = val; body end}} \\
    \finchsieve(cond \in E, body \in S) &:= \text{\mintinline{julia}{if cond; body end}} \\
    \finchblock(bodies\ldots \in S) &:= \text{\mintinline{julia}{begin; bodies... end}}
\end{align*}