
@article{psarras_landscape_2021,
	title = {The landscape of software for tensor computations},
	url = {http://arxiv.org/abs/2103.13756},
	abstract = {Tensors (also commonly seen as multi-linear operators or as multi-dimensional arrays) are ubiquitous in scientiﬁc computing and in data science, and so are the software eﬀorts for tensor operations. Particularly in recent years, we have observed an explosion in libraries, compilers, packages, and toolboxes; unfortunately these eﬀorts are very much scattered among the diﬀerent scientiﬁc domains, and inevitably suﬀer from replication, suboptimal implementations, and in many cases, limited visibility. As a ﬁrst step towards countering these ineﬃciencies, here we survey and loosely classify software packages related to tensor computations. Our aim is to assemble a comprehensive and up-to-date snapshot of the tensor software landscape, with the intention of helping both users and developers. Aware of the diﬃculties inherent in any multi-discipline survey, we very much welcome the reader’s help in amending and expanding our software list, which currently features 77 projects.},
	language = {en},
	urldate = {2022-04-29},
	journal = {arXiv:2103.13756 [cs]},
	author = {Psarras, Christos and Karlsson, Lars and Li, Jiajia and Bientinesi, Paolo},
	month = may,
	year = {2021},
	note = {arXiv: 2103.13756},
	keywords = {Computer Science - Mathematical Software},
	file = {Psarras et al. - 2021 - The landscape of software for tensor computations.pdf:/Users/willow/Zotero/storage/9FYH3IWU/Psarras et al. - 2021 - The landscape of software for tensor computations.pdf:application/pdf},
}

@article{hu_taichi_2019,
	title = {Taichi: a language for high-performance computation on spatially sparse data structures},
	volume = {38},
	issn = {0730-0301},
	shorttitle = {Taichi},
	url = {https://doi.org/10.1145/3355089.3356506},
	doi = {10.1145/3355089.3356506},
	abstract = {3D visual computing data are often spatially sparse. To exploit such sparsity, people have developed hierarchical sparse data structures, such as multi-level sparse voxel grids, particles, and 3D hash tables. However, developing and using these high-performance sparse data structures is challenging, due to their intrinsic complexity and overhead. We propose Taichi, a new data-oriented programming language for efficiently authoring, accessing, and maintaining such data structures. The language offers a high-level, data structure-agnostic interface for writing computation code. The user independently specifies the data structure. We provide several elementary components with different sparsity properties that can be arbitrarily composed to create a wide range of multi-level sparse data structures. This decoupling of data structures from computation makes it easy to experiment with different data structures without changing computation code, and allows users to write computation as if they are working with a dense array. Our compiler then uses the semantics of the data structure and index analysis to automatically optimize for locality, remove redundant operations for coherent accesses, maintain sparsity and memory allocations, and generate efficient parallel and vectorized instructions for CPUs and GPUs. Our approach yields competitive performance on common computational kernels such as stencil applications, neighbor lookups, and particle scattering. We demonstrate our language by implementing simulation, rendering, and vision tasks including a material point method simulation, finite element analysis, a multigrid Poisson solver for pressure projection, volumetric path tracing, and 3D convolution on sparse grids. Our computation-data structure decoupling allows us to quickly experiment with different data arrangements, and to develop high-performance data structures tailored for specific computational tasks. With 1{\textless}u{\textgreater}1{\textless}/u{\textgreater}0 th as many lines of code, we achieve 4.55× higher performance on average, compared to hand-optimized reference implementations.},
	number = {6},
	urldate = {2020-10-05},
	journal = {ACM Transactions on Graphics},
	author = {Hu, Yuanming and Li, Tzu-Mao and Anderson, Luke and Ragan-Kelley, Jonathan and Durand, Frédo},
	month = nov,
	year = {2019},
	keywords = {GPU computing, sparse data structures},
	pages = {201:1--201:16},
	file = {Full Text PDF:/Users/willow/Zotero/storage/LI4HK8PK/Hu et al. - 2019 - Taichi a language for high-performance computatio.pdf:application/pdf},
}

@article{langr_evaluation_2016,
	title = {Evaluation {Criteria} for {Sparse} {Matrix} {Storage} {Formats}},
	volume = {27},
	issn = {1558-2183},
	doi = {10.1109/TPDS.2015.2401575},
	abstract = {When authors present new storage formats for sparse matrices, they usually focus mainly on a single evaluation criterion, which is the performance of sparse matrix-vector multiplication (SpMV) in FLOPS. Though such an evaluation is essential, it does not allow to directly compare the presented format with its competitors. Moreover, in case that matrices are within an HPC application constructed in different formats, this criterion alone is not sufficient for the key decision whether or not to convert them into the presented format for the SpMV-based application phase. We establish ten evaluation criteria for sparse matrix storage formats, discuss their advantages and disadvantages, and provide general suggestions for format authors/evaluators to make their work more valuable for the HPC community.},
	number = {2},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Langr, Daniel and Tvrdík, Pavel},
	month = feb,
	year = {2016},
	note = {Conference Name: IEEE Transactions on Parallel and Distributed Systems},
	keywords = {evaluation criteria, Evaluation criterion, FLOPS, HPC application, Indexes, mathematics computing, matrix algebra, Matrix converters, matrix-vector multiplication, memory footprint, Memory management, nonzero matrix structure, parallel processing, Runtime, single evaluation criterion, Sparse matrices, sparse matrix, sparse matrix storage formats, sparse matrix-vector multiplication, SpMV-based application phase, Standards, storage format, test matrices, vectors},
	pages = {428--440},
	file = {IEEE Xplore Abstract Record:/Users/willow/Zotero/storage/DRZMJ4TJ/7036061.html:text/html;IEEE Xplore Abstract Record:/Users/willow/Zotero/storage/D75SXF9Z/7036061.html:text/html;IEEE Xplore Full Text PDF:/Users/willow/Zotero/storage/8IRGEGDG/Langr and Tvrdík - 2016 - Evaluation Criteria for Sparse Matrix Storage Form.pdf:application/pdf;IEEE Xplore Full Text PDF:/Users/willow/Zotero/storage/I3FNKNCF/Langr and Tvrdík - 2016 - Evaluation Criteria for Sparse Matrix Storage Form.pdf:application/pdf},
}

@article{kjolstad_tensor_2017,
	title = {The {Tensor} {Algebra} {Compiler}},
	volume = {1},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3133901},
	doi = {10.1145/3133901},
	abstract = {Tensor algebra is a powerful tool with applications in machine learning, data analytics, engineering and the physical sciences. Tensors are often sparse and compound operations must frequently be computed in a single kernel for performance and to save memory. Programmers are left to write kernels for every operation of interest, with different mixes of dense and sparse tensors in different formats. The combinations are infinite, which makes it impossible to manually implement and optimize them all. This paper introduces the first compiler technique to automatically generate kernels for any compound tensor algebra operation on dense and sparse tensors. The technique is implemented in a C++ library called taco. Its performance is competitive with best-in-class hand-optimized kernels in popular libraries, while supporting far more tensor operations.},
	number = {OOPSLA},
	urldate = {2019-11-20},
	journal = {Proc. ACM Program. Lang.},
	author = {Kjolstad, Fredrik and Kamil, Shoaib and Chou, Stephen and Lugato, David and Amarasinghe, Saman},
	month = oct,
	year = {2017},
	keywords = {code generation, iteration graphs, linear algebra, merge lattices, parallelism, performance, sparse data structures, tensor algebra, tensors},
	pages = {77:1--77:29},
	file = {ACM Full Text PDF:/Users/willow/Zotero/storage/M3YTNCUI/Kjolstad et al. - 2017 - The Tensor Algebra Compiler.pdf:application/pdf;Full Text PDF:/Users/willow/Zotero/storage/EZXEWXYJ/Kjolstad et al. - 2017 - The tensor algebra compiler.pdf:application/pdf;kjolstad-oopsla17-taco-preprint.pdf:/Users/willow/Zotero/storage/XUPL86I6/kjolstad-oopsla17-taco-preprint.pdf:application/pdf},
}

@inproceedings{ragan-kelley_halide_2013,
	address = {New York, NY, USA},
	series = {{PLDI} '13},
	title = {Halide: a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines},
	isbn = {978-1-4503-2014-6},
	shorttitle = {Halide},
	url = {http://doi.org/10.1145/2491956.2462176},
	doi = {10.1145/2491956.2462176},
	abstract = {Image processing pipelines combine the challenges of stencil computations and stream programs. They are composed of large graphs of different stencil stages, as well as complex reductions, and stages with global or data-dependent access patterns. Because of their complex structure, the performance difference between a naive implementation of a pipeline and an optimized one is often an order of magnitude. Efficient implementations require optimization of both parallelism and locality, but due to the nature of stencils, there is a fundamental tension between parallelism, locality, and introducing redundant recomputation of shared values. We present a systematic model of the tradeoff space fundamental to stencil pipelines, a schedule representation which describes concrete points in this space for each stage in an image processing pipeline, and an optimizing compiler for the Halide image processing language that synthesizes high performance implementations from a Halide algorithm and a schedule. Combining this compiler with stochastic search over the space of schedules enables terse, composable programs to achieve state-of-the-art performance on a wide range of real image processing pipelines, and across different hardware architectures, including multicores with SIMD, and heterogeneous CPU+GPU execution. From simple Halide programs written in a few hours, we demonstrate performance up to 5x faster than hand-tuned C, intrinsics, and CUDA implementations optimized by experts over weeks or months, for image processing applications beyond the reach of past automatic compilers.},
	urldate = {2021-09-10},
	booktitle = {Proceedings of the 34th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {Association for Computing Machinery},
	author = {Ragan-Kelley, Jonathan and Barnes, Connelly and Adams, Andrew and Paris, Sylvain and Durand, Frédo and Amarasinghe, Saman},
	month = jun,
	year = {2013},
	keywords = {autotuning, compiler, domain specific language, gpu, image processing, locality, optimization, parallelism, redundant computation, vectorization},
	pages = {519--530},
	file = {Full Text PDF:/Users/willow/Zotero/storage/QZF9XYFW/Ragan-Kelley et al. - 2013 - Halide a language and compiler for optimizing par.pdf:application/pdf},
}

@inproceedings{williams_optimization_2007,
	address = {New York, NY, USA},
	series = {{SC} '07},
	title = {Optimization of sparse matrix-vector multiplication on emerging multicore platforms},
	isbn = {978-1-59593-764-3},
	url = {http://doi.org/10.1145/1362622.1362674},
	doi = {10.1145/1362622.1362674},
	abstract = {We are witnessing a dramatic change in computer architecture due to the multicore paradigm shift, as every electronic device from cell phones to supercomputers confronts parallelism of unprecedented scale. To fully unleash the potential of these systems, the HPC community must develop multicore specific optimization methodologies for important scientific computations. In this work, we examine sparse matrix-vector multiply (SpMV) - one of the most heavily used kernels in scientific computing - across a broad spectrum of multicore designs. Our experimental platform includes the homogeneous AMD dual-core and Intel quad-core designs, the heterogeneous STI Cell, as well as the first scientific study of the highly multithreaded Sun Niagara2. We present several optimization strategies especially effective for the multicore environment, and demonstrate significant performance improvements compared to existing state-of-the-art serial and parallel SpMV implementations. Additionally, we present key insights into the architectural tradeoffs of leading multicore design strategies, in the context of demanding memory-bound numerical algorithms.},
	urldate = {2022-03-15},
	booktitle = {Proceedings of the 2007 {ACM}/{IEEE} conference on {Supercomputing}},
	publisher = {Association for Computing Machinery},
	author = {Williams, Samuel and Oliker, Leonid and Vuduc, Richard and Shalf, John and Yelick, Katherine and Demmel, James},
	month = nov,
	year = {2007},
	keywords = {Cellular phones, Computer architecture, Kernel, Multicore processing, Optimization methods, Parallel processing, Scientific computing, Sparse matrices, Sun, Supercomputers},
	pages = {1--12},
	file = {Full Text PDF:/Users/willow/Zotero/storage/G4VQIMPC/Williams et al. - 2007 - Optimization of sparse matrix-vector multiplicatio.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/willow/Zotero/storage/P7C29HUU/5348797.html:text/html;IEEE Xplore Abstract Record:/Users/willow/Zotero/storage/XVTJHNHK/5348797.html:text/html;IEEE Xplore Full Text PDF:/Users/willow/Zotero/storage/MLDMCFE7/Williams et al. - 2007 - Optimization of sparse matrix-vector multiplicatio.pdf:application/pdf},
}

@inproceedings{ahrens_looplets_2023,
	address = {New York, NY, USA},
	series = {{CGO} 2023},
	title = {Looplets: {A} {Language} for {Structured} {Coiteration}},
	isbn = {9798400701016},
	shorttitle = {Looplets},
	doi = {10.1145/3579990.3580020},
	abstract = {Real world arrays often contain underlying structure, such as sparsity, runs of repeated values, or symmetry. Specializing for structure yields significant speedups. But automatically generating efficient code for structured data is challenging, especially when arrays with different structure interact. We show how to abstract over array structures so that the compiler can generate code to coiterate over any combination of them. Our technique enables new array formats (such as 1DVBL for irregular clustered sparsity), new iteration strategies (such as galloping intersections), and new operations over structured data (such as concatenation or convolution).},
	urldate = {2023-04-03},
	booktitle = {Proceedings of the 21st {ACM}/{IEEE} {International} {Symposium} on {Code} {Generation} and {Optimization}},
	publisher = {Association for Computing Machinery},
	author = {Ahrens, Willow and Donenfeld, Daniel and Kjolstad, Fredrik and Amarasinghe, Saman},
	month = feb,
	year = {2023},
	keywords = {Array, Coiteration, Compressed, Sparse, Tensor},
	pages = {41--54},
	file = {Full Text PDF:/Users/willow/Zotero/storage/HUBGW7N9/Ahrens et al. - 2023 - Looplets A Language for Structured Coiteration.pdf:application/pdf},
}

@article{psarras_linear_2022,
	title = {The {Linear} {Algebra} {Mapping} {Problem}. {Current} state of linear algebra languages and libraries},
	volume = {48},
	issn = {0098-3500, 1557-7295},
	url = {http://arxiv.org/abs/1911.09421},
	doi = {10.1145/3549935},
	abstract = {We observe a disconnect between the developers and the end users of linear algebra libraries. On the one hand, the numerical linear algebra and the high-performance communities invest significant effort in the development and optimization of highly sophisticated numerical kernels and libraries, aiming at the maximum exploitation of both the properties of the input matrices, and the architectural features of the target computing platform. On the other hand, end users are progressively less likely to go through the error-prone and time consuming process of directly using said libraries by writing their code in C or Fortran; instead, languages and libraries such as Matlab, Julia, Eigen and Armadillo, which offer a higher level of abstraction, are becoming more and more popular. Users are given the opportunity to code matrix computations with a syntax that closely resembles the mathematical description; it is then a compiler or an interpreter that internally maps the input program to lower level kernels, as provided by libraries such as BLAS and LAPACK. Unfortunately, our experience suggests that in terms of performance, this translation is typically vastly suboptimal. In this paper, we first introduce the Linear Algebra Mapping Problem, and then investigate how effectively a benchmark of test problems is solved by popular high-level programming languages. Specifically, we consider Matlab, Octave, Julia, R, Armadillo (C++), Eigen (C++), and NumPy (Python); the benchmark is meant to test both standard compiler optimizations such as common subexpression elimination and loop-invariant code motion, as well as linear algebra specific optimizations such as optimal parenthesization of a matrix product and kernel selection for matrices with properties. The aim of this study is to give concrete guidelines for the development of languages and libraries that support linear algebra computations.},
	number = {3},
	urldate = {2023-10-03},
	journal = {ACM Transactions on Mathematical Software},
	author = {Psarras, Christos and Barthels, Henrik and Bientinesi, Paolo},
	month = sep,
	year = {2022},
	note = {arXiv:1911.09421 [cs]},
	keywords = {Computer Science - Mathematical Software, Computer Science - Programming Languages},
	pages = {1--30},
	file = {arXiv Fulltext PDF:/Users/willow/Zotero/storage/6APM5QY7/Psarras et al. - 2022 - The Linear Algebra Mapping Problem. Current state .pdf:application/pdf;arXiv.org Snapshot:/Users/willow/Zotero/storage/6JF2TJK5/1911.html:text/html},
}

@inproceedings{fegade_cora_2022,
	title = {The {CoRa} {Tensor} {Compiler}: {Compilation} for {Ragged} {Tensors} with {Minimal} {Padding}},
	volume = {4},
	url = {https://proceedings.mlsys.org/paper_files/paper/2022/file/afe8a4577080504b8bec07bbe4b2b9cc-Paper.pdf},
	booktitle = {Proceedings of {Machine} {Learning} and {Systems}},
	author = {Fegade, Pratik and Chen, Tianqi and Gibbons, Phillip and Mowry, Todd},
	editor = {Marculescu, D. and Chi, Y. and Wu, C.},
	year = {2022},
	pages = {721--747},
	file = {Fegade et al. - The CoRa Tensor Compiler Compilation for Ragged T.pdf:/Users/willow/Zotero/storage/8PT7K7GL/Fegade et al. - The CoRa Tensor Compiler Compilation for Ragged T.pdf:application/pdf},
}


@article{sze2017efficient,
  title={Efficient processing of deep neural networks: A tutorial and survey},
  author={Sze, Vivienne and Chen, Yu-Hsin and Yang, Tien-Ju and Emer, Joel S},
  journal={Proceedings of the IEEE},
  volume={105},
  number={12},
  pages={2295--2329},
  year={2017},
  publisher={Ieee}
}


@article{chou2018format,
  title={Format abstraction for sparse tensor algebra compilers},
  author={Chou, Stephen and Kjolstad, Fredrik and Amarasinghe, Saman},
  journal={Proceedings of the ACM on Programming Languages},
  volume={2},
  number={OOPSLA},
  pages={1--30},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@article{chou2022compilation,
  title={Compilation of dynamic sparse tensor algebra},
  author={Chou, Stephen and Amarasinghe, Saman},
  journal={Proceedings of the ACM on Programming Languages},
  volume={6},
  number={OOPSLA2},
  pages={1408--1437},
  year={2022},
  publisher={ACM New York, NY, USA}
}

@article{henry2021compilation,
  title={Compilation of sparse array programming models},
  author={Henry, Rawn and Hsu, Olivia and Yadav, Rohan and Chou, Stephen and Olukotun, Kunle and Amarasinghe, Saman and Kjolstad, Fredrik},
  journal={Proceedings of the ACM on Programming Languages},
  volume={5},
  number={OOPSLA},
  pages={1--29},
  year={2021},
  publisher={ACM New York, NY, USA}
}


@article{won2023unified,
  title={Unified Convolution Framework: A compiler-based approach to support sparse convolutions},
  author={Won, Jaeyeon and Hong, Changwan and Mendis, Charith and Emer, Joel and Amarasinghe, Saman},
  journal={Proceedings of Machine Learning and Systems},
  volume={5},
  year={2023}
}
